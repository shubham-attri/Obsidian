Shubham Attri 
https://github.com/shubham-attri/CSE508_Winter2024_A2_2021354
---

**1. Introduction**

 This report details the development and implementation of an Image and Text Retrieval System. The system is designed to retrieve relevant images and textual reviews based on user input. This report outlines the methodologies employed, the implementation process, and the various use cases covered by the system for the given assignment.

---

**2. Methodologies**

**a. Image Feature Extraction**
   - **Methodology**: Utilizes a pre-trained deep learning model, ResNet50, to extract high-level features from images.
   - **Implementation**: Images are preprocessed, resized, and normalized before being passed through ResNet50. The resulting feature vectors are stored and normalized for efficient retrieval.
   - **Use Cases Covered**: Image retrieval based on content similarity, such as finding visually similar images.

**b. Text Feature Extraction**
   - **Methodology**: Utilizes TF-IDF (Term Frequency-Inverse Document Frequency) vectorization to extract features from textual reviews.
   - **Implementation**: Textual reviews undergo preprocessing steps including tokenization, removal of stopwords and punctuation, and lowercasing. TF-IDF scores are computed and stored for each review.
   - **Use Cases Covered**: Text retrieval based on semantic similarity, such as finding reviews with similar content.

**c. Combined Retrieval**
   - **Methodology**: Integrates both image and text retrieval methodologies to provide combined results.
   - **Implementation**: Combined similarity scores are computed by considering both image and text similarities. The top relevant items are then returned to the user.
   - **Use Cases Covered**: Providing comprehensive retrieval results by considering both visual and textual content.

---

**3. Implementation**

The system is implemented in Python, making use of various libraries and tools:

- **Pandas**: For data manipulation and loading the dataset.
- **NumPy**: For numerical computations and array operations.
- **PIL**: For image processing tasks such as loading and resizing images.
- **Requests**: For fetching images from URLs.
- **OpenCV**: For additional image processing tasks.
- **TensorFlow/Keras**: For utilizing the ResNet50 model.
- **NLTK**: For natural language processing tasks such as text tokenization and stopword removal.
- **scikit-learn**: For TF-IDF vectorization and cosine similarity calculations.


```
import pandas as pd
import numpy as np
from PIL import Image
import requests
from io import BytesIO
import cv2
from tensorflow.keras.applications import ResNet50
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.spatial.distance import cosine
import pickle
import re
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string
import os
from sklearn.metrics.pairwise import cosine_similarity
# Load the dataset
data = pd.read_csv('A.csv')

# 1. Image Feature Extraction
# a. Image preprocessing
def preprocess_image(img_url):
    response = requests.get(img_url)
    if response.status_code == 200:
        try:
            img = Image.open(BytesIO(response.content))
            img = np.array(img)
            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            img = cv2.resize(img, (224, 224))
            img = np.array(img) / 255.0
            return img
        except (PIL.UnidentifiedImageError, Exception) as e:
            print(f"Error: {e}")
            return None
    else:
        print(f"Error: Failed to fetch image, status code: {response.status_code}")
        return None

# b. Extract features using ResNet50
resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

#Loading saved image features if available 
if os.path.exists('image_features.pkl'):
    with open('image_features.pkl','rb') as f:
        image_features = pickle.load(f)
        print("Image features loaded from 'image_features.pkl'!")
else:
    image_features = {}
    for index, row in data.iterrows():
        img_urls = row['Image'].strip("[]").split(', ')  # Split the image URLs
        features = []
        for img_url in img_urls:
            img_url.replace("''","")
            img_url = img_url[1:-1]
            #print(img_url)
            img = preprocess_image(img_url)
            if img is not None:
                feature = resnet_model.predict(np.expand_dims(img, axis=0))
                features.append(feature.squeeze())
        if features:
            image_features[row['Review Text']] = np.mean(features, axis=0)  # Store the average of features

    print("Image Features Retrieved Using ResNEt50")

    # c. Normalize features
    image_features = {k: v / np.linalg.norm(v) for k, v in image_features.items()}

    # Save image features
    with open('image_features.pkl', 'wb') as f:
        pickle.dump(image_features, f)

# 2. Text Feature Extraction

# a. Text preprocessing
def preprocess_text(text):
    if isinstance(text, str):
        # Lowercasing
        text = text.lower()

        # Tokenization
        tokens = word_tokenize(text)

        # Remove stopwords
        stop_words = set(stopwords.words('english'))
        tokens = [token for token in tokens if token not in stop_words]

        # Remove punctuations
        tokens = [token for token in tokens if token not in string.punctuation]

        # Remove blank space tokens
        tokens = [token for token in tokens if token.strip()]

        # Save preprocessed text
        ptext = ' '.join(tokens)

        return ptext
    else:
        return ''  # or any other default value you prefer


# b. Calculate TF-IDF tfidf_scores
if os.path.exists('tfidf_scores.pkl'):
    with open('tfidf_scores.pkl', 'rb') as f:
        vectorizer, tfidf_matrix = pickle.load(f)
        print("TF-IDF scores loaded from 'tfidf_scores.pkl'")
else:
    vectorizer = TfidfVectorizer()
    text_reviews = data['Review Text'].apply(preprocess_text)
    tfidf_matrix = vectorizer.fit_transform(text_reviews)

    # Save TF-IDF scores
    with open('tfidf_scores.pkl', 'wb') as f:
        pickle.dump((vectorizer, tfidf_matrix), f)

# 3. Image Retrieval and Text retrieval
# a. Image retrieval
def image_retrieval(query_img_urls, top_k=3):
    features = []
    for img_url in query_img_urls:
        img = preprocess_image(img_url.strip("'"))
        if img is not None:
            feature = resnet_model.predict(np.expand_dims(img, axis=0)).squeeze()
            features.append(feature.flatten()) # Flatten feature vectors

    if not features:
        return []
    
    query_feature = np.mean(features, axis=0)
    query_feature /= np.linalg.norm(query_feature)

    similarities = {}
    for k, v in image_features.items():
        similarities[k] = cosine(query_feature, v.flatten()) # Flatten image vectors

    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1])
    top_k_images = sorted_similarities[:top_k]
    return top_k_images

# b. Text retrieval
def text_retrieval(query_text, top_k=3):
    query_text = preprocess_text(query_text)
    query_tfidf = vectorizer.transform([query_text])

    similarities = cosine_similarity(query_tfidf, tfidf_matrix).squeeze()
    top_k_indices = similarities.argsort()[-top_k:][::-1]
    top_k_reviews = [(data.iloc[idx]['Review Text'], similarities[idx]) for idx in top_k_indices]
    return top_k_reviews

# 4. Combined Retrieval
def combined_retrieval(query_img_urls, query_text, top_k=3):
    image_results = image_retrieval(query_img_urls, top_k)
    text_results = text_retrieval(query_text, top_k)

    combined_results = []
    for review, img_sim in image_results:
        for review_text, text_sim in text_results:
            if review == review_text:
                combined_sim = (img_sim + text_sim) / 2
                combined_results.append((review, combined_sim))

    combined_results = sorted(combined_results, key=lambda x: x[1], reverse=True)[:top_k]
    return combined_results

# 5. Results and Analysis

def analysingquery(query_img_urls, query_text):

    top_k = 3
    
    # Image retrieval
    print('Image Retrieval:')
    try:
        image_results = image_retrieval(query_img_urls, top_k)
        if not image_results:
            print("No similar images found.") 
        else:
            for review, img_sim in image_results:
                print(f'Review: {review}')
                print(f'Cosine Similarity: {1 - img_sim}')
                print('---')
    except Exception as e:
        print("Error in image retrieval:", e)
        
    # Text retrieval
    print('\nText Retrieval:')
    try: 
        text_results = text_retrieval(query_text, top_k)
        if not text_results:
            print("No similar reviews found.")
        else:
            for review_text, text_sim in text_results:
                print(f'Review: {review_text}')
                print(f'Cosine Similarity: {text_sim}')
                print('---')
    except Exception as e:
        print("Error in text retrieval:", e)

    # Combined retrieval
    print('\nCombined Retrieval:')
    try:
        combined_results = combined_retrieval(query_img_urls, query_text, top_k)
        if not combined_results:
            print("No similar (image, review) pairs found.")
        else:
            for review, combined_sim in combined_results:
                print(f'Review: {review}')
                print(f'Combined Similarity Score: {combined_sim}')
                print('---')
    except Exception as e:
        print("Error in combined retrieval:", e)

if __name__ == "__main__":

    n = int(input("Enter the number of queries: "))
    
    for i in range(n):
        image_links = input("Enter the links of the images (comma-separated): ").split(',') 
        text_review = input("Enter the review: ")
        
        analysingquery(image_links, text_review)


```

---

**4. Use Cases Covered**

**a. Image Retrieval**
   - **Case**: A user wants to find visually similar images to a given input image.
   - **Implementation**: The system retrieves images based on visual features extracted by ResNet50, providing a list of visually similar images.
**b. Text Retrieval**
   - **Case**: A user wants to find reviews similar to a provided text review.
   - **Implementation**: The system retrieves reviews based on semantic similarity, using TF-IDF vectors and cosine similarity calculations.

**c. Combined Retrieval**
   - **Case**: A user wants comprehensive results considering both image and text similarities.
   - **Implementation**: The system combines results from image and text retrieval methods, providing a holistic view of relevant items.

---

**5. Analysis**

The below screenshot contains multiple link inputs separated by comma:
![[Screenshot 2024-03-04 at 9.50.12 AM.png]]

The below contains a single url and the text review:
![[Screenshot 2024-03-04 at 9.53.28 AM.png]]

The below contains a query with invalid url:
![[Pasted image 20240304095510.png]]

***When we wrote the text query with the exact same review test from the database the cosine similarity is 0.99, when we gave a invalid url link it gave a 0 cosine similarity.***
****

The Image and Text Retrieval System developed in this project provides a robust solution for retrieving relevant content based on user queries. By leveraging deep learning for image feature extraction and TF-IDF for text feature extraction, the system offers versatile retrieval capabilities. The combined retrieval method further enhances the user experience by providing comprehensive results. The system demonstrates the effectiveness of integrating multiple methodologies to address diverse retrieval needs.

--- 

**References**

https://www.tensorflow.org/
https://scikit-learn.org/
https://www.nltk.org/
https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f
https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction
https://www.tensorflow.org/tutorials/images/transfer_learning
https://chat.openai.com/share/6a06f99f-2096-42b1-bd6e-f97d17bcbccc

